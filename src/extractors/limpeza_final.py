"""
Limpeza Final de Leiloeiros - ExtraÃ§Ã£o Direta de Tabela com PDFPlumber
Extrai dados limpos do PDF com recorte preciso e filtros rigorosos.
"""
import pdfplumber
import json
import re
from pathlib import Path
from typing import List, Dict, Optional
import pandas as pd

class PDFTableExtractor:
    """Extrai tabela de leiloeiros com recorte preciso e limpeza rigorosa"""
    
    def __init__(self, pdf_path: str = "docs/Leiloeiros de SP.pdf"):
        self.pdf_path = Path(pdf_path)
        self.noise_patterns = [
            'Adriano Duarte',
            'duarte.adriano',
            'Licensed to',
            '28255301828',
            'Nome',
            'MatrÃ­cula',
            'MATRÃCULA',
            'NOME',
            'CPF',
            'CNPJ'
        ]
        
    def is_noise(self, text: str) -> bool:
        """Verifica se o texto Ã© ruÃ­do/marca d'Ã¡gua"""
        if not text or pd.isna(text):
            return True
        
        text_lower = str(text).lower()
        
        # Verifica padrÃµes de ruÃ­do
        for pattern in self.noise_patterns:
            if pattern.lower() in text_lower:
                return True
        
        # Verifica se Ã© cabeÃ§alho da tabela
        if text_lower in ['nome', 'matrÃ­cula', 'matricula', 'cpf', 'cnpj']:
            return True
        
        return False
    
    def is_address(self, text: str) -> bool:
        """Verifica se o texto parece um endereÃ§o"""
        if not text or pd.isna(text):
            return False
        
        text_upper = str(text).upper()
        address_keywords = [
            'RUA', 'AV', 'AVENIDA', 'ALAMEDA', 'TRAVESSA', 'RODOVIA',
            'KM', 'NÂº', 'NÂ°', 'S/N', 'APTO', 'APARTAMENTO', 'SALA',
            'ANDAR', 'BLOCO', 'CONJUNTO', 'LOTE', 'QUADRA', 'CEP',
            'BAIRRO', 'CIDADE', 'ESTADO', 'LOGRADOURO'
        ]
        
        for keyword in address_keywords:
            if keyword in text_upper:
                return True
        
        return False
    
    def extract_text_from_page(self, page) -> str:
        """
        Extrai texto de uma pÃ¡gina com recorte preciso
        """
        page_height = page.height
        page_width = page.width
        
        # Define bounding box que ignora 15% do topo e 10% da base
        top_margin = page_height * 0.15  # 15% para cabeÃ§alho
        bottom_margin = page_height * 0.90  # 10% para rodapÃ©
        
        bbox = (0, top_margin, page_width, bottom_margin)
        
        # Extrai texto da Ã¡rea recortada
        cropped_page = page.within_bbox(bbox)
        text = cropped_page.extract_text()
        
        return text if text else ""
    
    def find_email_column(self, row: List[str]) -> Optional[int]:
        """Encontra a coluna que contÃ©m email"""
        if not row:
            return None
        
        for i, cell in enumerate(row):
            if cell and '@' in str(cell):
                return i
        
        return None
    
    def clean_name(self, name: str) -> str:
        """Limpa o nome do leiloeiro"""
        if not name or pd.isna(name):
            return ""
        
        name_str = str(name)
        
        # Remove nÃºmeros no final
        name_str = re.sub(r'[\d\s\-\./]+$', '', name_str)
        
        # Remove caracteres especiais no inÃ­cio
        name_str = re.sub(r'^[_\W]+', '', name_str)
        
        # Remove espaÃ§os extras
        name_str = name_str.strip()
        
        # Capitaliza se tudo for minÃºsculo
        if name_str and name_str.islower():
            words = name_str.split()
            capitalized_words = [word.capitalize() for word in words]
            name_str = ' '.join(capitalized_words)
        
        return name_str
    
    def extract_email(self, text: str) -> str:
        """Extrai email do texto"""
        if not text:
            return ""
        
        email_match = re.search(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', text)
        if email_match:
            email = email_match.group(0).lower()
            email = re.sub(r'\s+', '', email)
            return email
        
        return ""
    
    def process_text(self, text: str, page_num: int) -> List[Dict]:
        """Processa texto extraÃ­do para encontrar leiloeiros"""
        processed_rows = []
        
        if not text:
            return processed_rows
        
        lines = text.split('\n')
        
        for line in lines:
            line = line.strip()
            
            # Ignora linhas vazias
            if not line:
                continue
            
            # Ignora ruÃ­do
            if self.is_noise(line):
                continue
            
            # Ignora endereÃ§os
            if self.is_address(line):
                continue
            
            # Procura email na linha
            email_match = re.search(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', line)
            email = email_match.group(0).lower() if email_match else ""
            
            # Remove email da linha para obter nome
            nome_line = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', '', line)
            nome_line = nome_line.strip()
            
            # Se nÃ£o tem email, tenta identificar nome
            if not email and len(nome_line) > 3:
                # Verifica se parece um nome (nÃ£o tem nÃºmeros, nÃ£o Ã© muito curto)
                if not re.search(r'\d', nome_line) and len(nome_line.split()) >= 2:
                    nome_limpo = self.clean_name(nome_line)
                    if nome_limpo and len(nome_limpo) > 3:
                        record = {
                            'nome': nome_limpo,
                            'email': "",
                            'pagina': page_num,
                            'fonte': 'pdf_text_extractor'
                        }
                        processed_rows.append(record)
            elif email:
                # Tem email, extrai nome
                nome_limpo = self.clean_name(nome_line)
                if not nome_limpo or len(nome_limpo) < 3:
                    # Se nÃ£o conseguiu extrair nome, usa parte do email
                    nome_parts = email.split('@')[0].split('.')
                    nome_limpo = ' '.join([part.capitalize() for part in nome_parts if part])
                
                if nome_limpo and len(nome_limpo) > 3:
                    record = {
                        'nome': nome_limpo,
                        'email': email,
                        'pagina': page_num,
                        'fonte': 'pdf_text_extractor'
                    }
                    processed_rows.append(record)
        
        return processed_rows
    
    def extract_all_pages(self) -> List[Dict]:
        """Extrai dados de todas as pÃ¡ginas"""
        print(f"ğŸ“„ Extraindo texto de: {self.pdf_path.name}")
        
        if not self.pdf_path.exists():
            print(f"âŒ Arquivo nÃ£o encontrado: {self.pdf_path}")
            return []
        
        all_data = []
        
        try:
            with pdfplumber.open(self.pdf_path) as pdf:
                total_pages = len(pdf.pages)
                
                print(f"ğŸ“– Processando {total_pages} pÃ¡ginas...")
                
                for page_num in range(total_pages):
                    print(f"   ğŸ” PÃ¡gina {page_num + 1}/{total_pages}...")
                    page = pdf.pages[page_num]
                    
                    # Extrai texto da pÃ¡gina
                    text = self.extract_text_from_page(page)
                    
                    if text:
                        # Processa texto
                        processed_rows = self.process_text(text, page_num + 1)
                        all_data.extend(processed_rows)
                        print(f"   âœ… {len(processed_rows)} leiloeiros encontrados")
                    else:
                        print(f"   âš ï¸  Nenhum texto extraÃ­do")
                
                print(f"\nâœ… Total extraÃ­do: {len(all_data)} registros")
                
        except Exception as e:
            print(f"âŒ Erro ao processar PDF: {str(e)}")
            import traceback
            traceback.print_exc()
        
        return all_data
    
    def deduplicate_data(self, data: List[Dict]) -> List[Dict]:
        """Remove duplicados baseado no nome e email"""
        print("\nğŸ” Removendo duplicados...")
        
        seen_records = set()
        unique_data = []
        
        for record in data:
            nome = record['nome']
            email = record['email']
            
            # Cria chave Ãºnica
            record_key = f"{nome}_{email}"
            
            if record_key not in seen_records:
                seen_records.add(record_key)
                unique_data.append(record)
        
        print(f"âœ… ApÃ³s deduplicaÃ§Ã£o: {len(unique_data)} registros Ãºnicos")
        return unique_data
    
    def save_results(self, data: List[Dict], output_path: str = "data/processed/lista_final_600.json"):
        """Salva resultados em JSON"""
        print(f"\nğŸ’¾ Salvando dados finais...")
        
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Dados salvos em: {output_path}")
        
        # EstatÃ­sticas
        df = pd.DataFrame(data)
        
        total = len(df)
        com_email = df[df['email'] != ''].shape[0]
        
        print(f"\nğŸ“Š EstatÃ­sticas finais:")
        print(f"   - Total de leiloeiros: {total}")
        print(f"   - Com email: {com_email} ({com_email/total*100:.1f}%)")
        print(f"   - Sem email: {total - com_email} ({(total - com_email)/total*100:.1f}%)")
        
        # Primeiros 10 registros para verificaÃ§Ã£o
        print(f"\nğŸ” Primeiros 10 registros:")
        for i, record in enumerate(data[:10], 1):
            print(f"   {i}. {record['nome'][:30]}...")
            if record['email']:
                print(f"      ğŸ“§ {record['email']}")
        
        return output_file
    
    def run_extraction(self):
        """Executa extraÃ§Ã£o completa"""
        print("=" * 70)
        print("ğŸ”§ LIMPEZA FINAL - EXTRAÃ‡ÃƒO DE TABELA COM PDFPLUMBER")
        print("=" * 70)
        
        # Extrai dados
        raw_data = self.extract_all_pages()
        
        if not raw_data:
            print("âŒ Nenhum dado extraÃ­do")
            return None
        
        # Remove duplicados
        unique_data = self.deduplicate_data(raw_data)
        
        # Salva resultados
        output_path = self.save_results(unique_data)
        
        # AnÃ¡lise adicional
        print("\nğŸ“ˆ ANÃLISE DETALHADA:")
        print("-" * 50)
        
        df = pd.DataFrame(unique_data)
        
        # DistribuiÃ§Ã£o por pÃ¡gina
        print(f"\nğŸ“– DistribuiÃ§Ã£o por pÃ¡gina:")
        page_counts = df['pagina'].value_counts().sort_index()
        for pagina, count in page_counts.items():
            print(f"   PÃ¡gina {pagina}: {count} leiloeiros")
        
        # Nomes mais comuns
        print(f"\nğŸ” Nomes mais frequentes:")
        nome_counts = df['nome'].value_counts().head(5)
        for nome, count in nome_counts.items():
            print(f"   â€¢ {nome[:25]}...: {count} ocorrÃªncias")
        
        print(f"\nğŸ¯ Meta: ~600 leiloeiros")
        print(f"ğŸ“Š Atual: {len(unique_data)} leiloeiros extraÃ­dos")
        
        print("\nâœ… ExtraÃ§Ã£o final concluÃ­da!")
        return output_path

def main():
    """FunÃ§Ã£o principal"""
    extractor = PDFTableExtractor()
    output_path = extractor.run_extraction()
    
    if output_path:
        print(f"\nğŸ“ Arquivo gerado: {output_path}")
        print(f"ğŸš€ PrÃ³ximo passo: Execute o enriquecimento e classificaÃ§Ã£o")
        print(f"   python src/processors/enrich_clean_data.py")
        print(f"   python src/processors/rank_final.py")
    else:
        print("\nâŒ Falha na extraÃ§Ã£o")

if __name__ == "__main__":
    main()
